//Script GUID:a14d24a8-5fef-496e-8a9c-f6499ded82d4
//Used for tracking history

/*
 * This is where we process the main body of telemetry data coming into asimov from
 * clients running ChakraFull. We already extracted the data from the asimov's main
 * telemetry stream into the cookedchakratelemetry files; additionally, we have set
 * up the device and url data files, which we will now correlate with the usage and
 * polyfill data. The output of this file is a large number of fairly wide rows, so
 * another step is needed after it to aggregate on it to get site-specific info.
 */

// We use a couple functions from this to do our processing.
#CS
using Microsoft.SCOPE.Types;
using System;
using System.Collections.Generic;
using System.IO;
using System.Text;
using System.Text.RegularExpressions;
using ScopeRuntime;

public class AssocProcessor : Processor
{
    // Slightly processed versions of header files from Chakra
    private static readonly string telemetryConfig = @"
<<<HEADER_FILE>>>
        ";

    // To save on data size, we transmit the CRC32 hashes of the names for fields in the associative
    // arrays. This reduces the volume of data that we send, and simplifies some handling. We need a
    // way to convert back, so we include the headers that define the symbols above, and then do the
    // same operation to re-generate the hash.
    private static readonly UInt64[] crc_table = {
    0x00000000, 0x77073096, 0xEE0E612C, 0x990951BA, 0x076DC419, 0x706AF48F, 0xE963A535, 0x9E6495A3, 0x0EDB8832, 0x79DCB8A4, 0xE0D5E91E, 0x97D2D988, 0x09B64C2B, 0x7EB17CBD, 0xE7B82D07, 0x90BF1D91,
    0x1DB71064, 0x6AB020F2, 0xF3B97148, 0x84BE41DE, 0x1ADAD47D, 0x6DDDE4EB, 0xF4D4B551, 0x83D385C7, 0x136C9856, 0x646BA8C0, 0xFD62F97A, 0x8A65C9EC, 0x14015C4F, 0x63066CD9, 0xFA0F3D63, 0x8D080DF5,
    0x3B6E20C8, 0x4C69105E, 0xD56041E4, 0xA2677172, 0x3C03E4D1, 0x4B04D447, 0xD20D85FD, 0xA50AB56B, 0x35B5A8FA, 0x42B2986C, 0xDBBBC9D6, 0xACBCF940, 0x32D86CE3, 0x45DF5C75, 0xDCD60DCF, 0xABD13D59,
    0x26D930AC, 0x51DE003A, 0xC8D75180, 0xBFD06116, 0x21B4F4B5, 0x56B3C423, 0xCFBA9599, 0xB8BDA50F, 0x2802B89E, 0x5F058808, 0xC60CD9B2, 0xB10BE924, 0x2F6F7C87, 0x58684C11, 0xC1611DAB, 0xB6662D3D,
    0x76DC4190, 0x01DB7106, 0x98D220BC, 0xEFD5102A, 0x71B18589, 0x06B6B51F, 0x9FBFE4A5, 0xE8B8D433, 0x7807C9A2, 0x0F00F934, 0x9609A88E, 0xE10E9818, 0x7F6A0DBB, 0x086D3D2D, 0x91646C97, 0xE6635C01,
    0x6B6B51F4, 0x1C6C6162, 0x856530D8, 0xF262004E, 0x6C0695ED, 0x1B01A57B, 0x8208F4C1, 0xF50FC457, 0x65B0D9C6, 0x12B7E950, 0x8BBEB8EA, 0xFCB9887C, 0x62DD1DDF, 0x15DA2D49, 0x8CD37CF3, 0xFBD44C65,
    0x4DB26158, 0x3AB551CE, 0xA3BC0074, 0xD4BB30E2, 0x4ADFA541, 0x3DD895D7, 0xA4D1C46D, 0xD3D6F4FB, 0x4369E96A, 0x346ED9FC, 0xAD678846, 0xDA60B8D0, 0x44042D73, 0x33031DE5, 0xAA0A4C5F, 0xDD0D7CC9,
    0x5005713C, 0x270241AA, 0xBE0B1010, 0xC90C2086, 0x5768B525, 0x206F85B3, 0xB966D409, 0xCE61E49F, 0x5EDEF90E, 0x29D9C998, 0xB0D09822, 0xC7D7A8B4, 0x59B33D17, 0x2EB40D81, 0xB7BD5C3B, 0xC0BA6CAD,
    0xEDB88320, 0x9ABFB3B6, 0x03B6E20C, 0x74B1D29A, 0xEAD54739, 0x9DD277AF, 0x04DB2615, 0x73DC1683, 0xE3630B12, 0x94643B84, 0x0D6D6A3E, 0x7A6A5AA8, 0xE40ECF0B, 0x9309FF9D, 0x0A00AE27, 0x7D079EB1,
    0xF00F9344, 0x8708A3D2, 0x1E01F268, 0x6906C2FE, 0xF762575D, 0x806567CB, 0x196C3671, 0x6E6B06E7, 0xFED41B76, 0x89D32BE0, 0x10DA7A5A, 0x67DD4ACC, 0xF9B9DF6F, 0x8EBEEFF9, 0x17B7BE43, 0x60B08ED5,
    0xD6D6A3E8, 0xA1D1937E, 0x38D8C2C4, 0x4FDFF252, 0xD1BB67F1, 0xA6BC5767, 0x3FB506DD, 0x48B2364B, 0xD80D2BDA, 0xAF0A1B4C, 0x36034AF6, 0x41047A60, 0xDF60EFC3, 0xA867DF55, 0x316E8EEF, 0x4669BE79,
    0xCB61B38C, 0xBC66831A, 0x256FD2A0, 0x5268E236, 0xCC0C7795, 0xBB0B4703, 0x220216B9, 0x5505262F, 0xC5BA3BBE, 0xB2BD0B28, 0x2BB45A92, 0x5CB36A04, 0xC2D7FFA7, 0xB5D0CF31, 0x2CD99E8B, 0x5BDEAE1D,
    0x9B64C2B0, 0xEC63F226, 0x756AA39C, 0x026D930A, 0x9C0906A9, 0xEB0E363F, 0x72076785, 0x05005713, 0x95BF4A82, 0xE2B87A14, 0x7BB12BAE, 0x0CB61B38, 0x92D28E9B, 0xE5D5BE0D, 0x7CDCEFB7, 0x0BDBDF21,
    0x86D3D2D4, 0xF1D4E242, 0x68DDB3F8, 0x1FDA836E, 0x81BE16CD, 0xF6B9265B, 0x6FB077E1, 0x18B74777, 0x88085AE6, 0xFF0F6A70, 0x66063BCA, 0x11010B5C, 0x8F659EFF, 0xF862AE69, 0x616BFFD3, 0x166CCF45,
    0xA00AE278, 0xD70DD2EE, 0x4E048354, 0x3903B3C2, 0xA7672661, 0xD06016F7, 0x4969474D, 0x3E6E77DB, 0xAED16A4A, 0xD9D65ADC, 0x40DF0B66, 0x37D83BF0, 0xA9BCAE53, 0xDEBB9EC5, 0x47B2CF7F, 0x30B5FFE9,
    0xBDBDF21C, 0xCABAC28A, 0x53B39330, 0x24B4A3A6, 0xBAD03605, 0xCDD70693, 0x54DE5729, 0x23D967BF, 0xB3667A2E, 0xC4614AB8, 0x5D681B02, 0x2A6F2B94, 0xB40BBE37, 0xC30C8EA1, 0x5A05DF1B, 0x2D02EF8D
    };
    private static UInt64 CRC32(byte[] input)
    {
        UInt64 crc = (UInt64)(0xFFFFFFFF);
        int i = 0;
        while (i < input.Length && input[i] != '\0')
        {
            crc = (crc >> 8) ^ crc_table[(crc ^ input[i]) & 0xFF];
            i++;
        }
        return crc ^ (UInt64)(0xFFFFFFFF);
    }
    // We don't change the result schema per row, enabling optimizations
    public override bool ConstantResultSchema
    {
        get
        {
            return true;
        } 
    }
    // One input row results in one output row, enabling optimizations
    public override bool RowLevelProcessor
    {
        get
        {
            return true;
        }
    }

    // Dictionaries to lookup known values from data sets
    SortedDictionary<string, SortedDictionary<UInt64, string>> validmappings = new SortedDictionary<string, SortedDictionary<UInt64, string>>();
    SortedDictionary<UInt64, string> additionalfields = new SortedDictionary<UInt64, string>();

    // Initialize some internal structures (once)
    bool hasinitialized = false;
    private void InternalInitialize()
    {
        if(!hasinitialized)
        {
            hasinitialized = true;
            Regex nocomments = new Regex(@"//[^\n]*\n");
            String uncommented = nocomments.Replace(telemetryConfig, "");
            Regex builtins = new Regex(@"((?<Type>BLOCK_START)\((?<BlockName>[a-zA-Z0-9_]*), *(?<BlockCount>[0-9]*)\))|((?<Type>ENTRY_BUILTIN)\((?<EMCAVersion>[a-zA-Z0-9_]*), *(?<BaseObject>[a-zA-Z0-9_]*), *(?<LinkType>[a-zA-Z0-9_]*), *(?<FunctionName>[a-zA-Z0-9_]*)\))|((?<Type>ENTRY_LANGFEATURE)\((?<EMCAVersion>[a-zA-Z0-9_]*), *(?<PointName>[a-zA-Z0-9_]*)\))|((?<Type>ENTRY_TELPOINT)\((?<PointName>[a-zA-Z0-9_]*)\))");
            String currentBlock = "";
            foreach ( Match match in builtins.Matches(uncommented) )
            {
                switch (match.Groups["Type"].Value)
                {
                    case "BLOCK_START":
                        currentBlock = match.Groups["BlockName"].Value;
                        validmappings[currentBlock] = new SortedDictionary<UInt64, string>();
                        break;
                    case "ENTRY_BUILTIN":
                        {
                            string fieldtag = match.Groups["BaseObject"].Value + "_" + match.Groups["LinkType"].Value + "_" + match.Groups["FunctionName"].Value;
                            UInt64 hash = CRC32(Encoding.ASCII.GetBytes(fieldtag));
                            validmappings[currentBlock][hash] = fieldtag;
                        }
                        break;
                    case "ENTRY_LANGFEATURE":
                    case "ENTRY_TELPOINT":
                        {
                            string fieldtag = match.Groups["PointName"].Value;
                            UInt64 hash = CRC32(Encoding.ASCII.GetBytes(fieldtag));
                            additionalfields[hash] = fieldtag;
                        }
                        break;
                }
            }
        }
    }

    // Prepare to handle data
    public override void Initialize(RowSet left, RowSet right, string[] args)
    {
        InternalInitialize();
    }

    // Construct a schema from the known information for the output rows
    public override Schema GetOutputSchemaAtCompileTime(string[] requestedColumns, string[] args, Schema input)
    {
        Schema resultSchema = input.CloneWithSource();
        Regex nocomments = new Regex(@"//[^\n]*\n");
        String uncommented = nocomments.Replace(telemetryConfig, "");
        Regex builtins = new Regex(@"((?<Type>BLOCK_START)\((?<BlockName>[a-zA-Z0-9_]*), *(?<BlockCount>[0-9]*)\))|((?<Type>ENTRY_BUILTIN)\((?<EMCAVersion>[a-zA-Z0-9_]*), *(?<BaseObject>[a-zA-Z0-9_]*), *(?<LinkType>[a-zA-Z0-9_]*), *(?<FunctionName>[a-zA-Z0-9_]*)\))|((?<Type>ENTRY_LANGFEATURE)\((?<EMCAVersion>[a-zA-Z0-9_]*), *(?<PointName>[a-zA-Z0-9_]*)\))|((?<Type>ENTRY_TELPOINT)\((?<PointName>[a-zA-Z0-9_]*)\))");
        String currentBlock = "";
        resultSchema = new Schema();
        resultSchema.Add(new ColumnInfo("Domain", typeof(string)));
        resultSchema.Add(new ColumnInfo("ApplicationName", typeof(string)));
        resultSchema.Add(new ColumnInfo("MachineConfigId", typeof(string)));
        resultSchema.Add(new ColumnInfo("ActivityId", typeof(string)));
        foreach (Match match in builtins.Matches(uncommented))
        {
            switch (match.Groups["Type"].Value)
            {
                case "BLOCK_START":
                    currentBlock = match.Groups["BlockName"].Value;
                    break;
                case "ENTRY_BUILTIN":
                    string fieldtag = match.Groups["BaseObject"].Value + "_" + match.Groups["LinkType"].Value + "_" + match.Groups["FunctionName"].Value;
                    resultSchema.Add(new ColumnInfo(fieldtag + "_present", typeof(bool)));
                    resultSchema.Add(new ColumnInfo(fieldtag + "_props", typeof(int)));
                    resultSchema.Add(new ColumnInfo(fieldtag + "_callCount", typeof(int)));
                    resultSchema.Add(new ColumnInfo(fieldtag + "_dMCallCount", typeof(int)));
                    break;
                case "ENTRY_LANGFEATURE":
                case "ENTRY_TELPOINT":
                    resultSchema.Add(new ColumnInfo(match.Groups["PointName"].Value + "_present", typeof(bool)));
                    resultSchema.Add(new ColumnInfo(match.Groups["PointName"].Value, typeof(int)));
                    break;
            }
        }
        return resultSchema;
    }

    // Get an array from a telemetry-encoded version, which separates elements with null characters
    private UInt64[] ExtractArray(string input)
    {
        string[] keystr = input.Split(new char[] { '\0' });
        UInt64[] keyhashes = new UInt64[keystr.Length];
        for (int i = 0; i < keystr.Length; i++)
        {
            try
            {
                keyhashes[i] = keystr[i] == null ? 0 : (keystr[i] == "" ? 0 : UInt64.Parse(keystr[i]));
            } catch (Exception e)
            {
                keyhashes[i] = 0;
            }
        }
        return keyhashes;
    }

    // Generator for output rows from input rows
    public override IEnumerable<Row> Process(RowSet input, Row outputRow, string[] args)
    {
        InternalInitialize();
        // Loop over all rows sent to this vertex, and process each to conform to the schema
        foreach(Row row in input.Rows)
        {
            outputRow["Domain"].Set(row["Domain"] != null ? row["Domain"].String : "");
            outputRow["ApplicationName"].Set(row["ApplicationName"] != null ? row["ApplicationName"].String : "");
            outputRow["MachineConfigId"].Set(row["MachineConfigId"] != null ? row["MachineConfigId"].String : "");
            outputRow["ActivityId"].Set(row["ActivityId"] != null ? row["ActivityId"].String : "");
            // handle the assoc arrays
            foreach(string str in validmappings.Keys)
            {
                UInt64[] keyhashes = ExtractArray(row[str+"_arr_keys_item"].String);
                UInt64[] props = ExtractArray(row[str+"_arr_props_item"].String);
                UInt64[] callCount = ExtractArray(row[str+"_arr_callCount_item"].String);
                UInt64[] dmCallCount = ExtractArray(row[str+"_arr_dmCallCount_item"].String);
                foreach(UInt64 hash in validmappings[str].Keys)
                {
                    bool found = false;
                    for(int i=0;i<keyhashes.Length;i++)
                    {
                        if(keyhashes[i] == hash)
                        {
                            found = true;
                            outputRow[validmappings[str][hash] + "_present"].Set(true);
                            outputRow[validmappings[str][hash] + "_props"].Set(i < props.Length ? props[i] : 0);
                            outputRow[validmappings[str][hash] + "_callCount"].Set(i < callCount.Length ? callCount[i] : 0);
                            outputRow[validmappings[str][hash] + "_dMCallCount"].Set(i < dmCallCount.Length ? dmCallCount[i] : 0);
                            break;
                        }
                    }
                    if (!found)
                    {
                        outputRow[validmappings[str][hash] + "_present"].Set(false);
                        outputRow[validmappings[str][hash] + "_props"].Set(0);
                        outputRow[validmappings[str][hash] + "_callCount"].Set(0);
                        outputRow[validmappings[str][hash] + "_dMCallCount"].Set(0);
                    }
                }
            }
            // the telpoints and langfeatures can appear either as a long set of individiual additional elements
            // (the old way of handling them) or as entries in a separate "uncategorized" map. We want to handle
            // both potential set-ups.

            if(row["UncategorizedNameTags"] != null && row["UncategorizedData"] != null) {
                // handle as a map of hash->count
                UInt64[] keyhashes = ExtractArray(row["UncategorizedNameTags"].String);
                UInt64[] counts = ExtractArray(row["UncategorizedFieldCount"].String);
                foreach(UInt64 hash in additionalfields.Keys) {
                    bool found = false;
                    string str = additionalfields[hash];
                    for(int i=0;i<keyhashes.Length;i++) {
                        if(keyhashes[i] == hash) {
                            found = true;
                            outputRow[str + "_present"].Set(true);
                            outputRow[str].Set(i < counts.Length ? counts[i] : 0);
                            break;
                        }
                    }
                    if(!found) {
                        outputRow[str + "_present"].Set(false);
                        outputRow[str].Set(0);
                    }
                }
            } else {
                // handle as a number of fields
                foreach(UInt64 hash in additionalfields.Keys)
                {
                    string str = additionalfields[hash];
                    if(row[str] == null) {
                        outputRow[str + "_present"].Set(false);
                        outputRow[str].Set(0);
                    } else {
                        outputRow[str + "_present"].Set(true);
                        outputRow[str].Set(row[str].String == "" ? 0 : UInt64.Parse(row[str].String));
                    }
                }
            }

            yield return outputRow;
        }
    }

    // We don't really care about what's requested, so this is the same as the compile-time version
    public override Schema Produces(string[] requestedColumns, string[] args, Schema input)
    {
        return GetOutputSchemaAtCompileTime(requestedColumns, args, input);
    }
}
#ENDCS

// hook up to the asimov date inputs, so that back runs work properly
#DECLARE startDate DateTime = IF("@@startDate@@".StartsWith("@@"), DateTime.UtcNow, DateTime.Parse("@@startDate@@"));
#DECLARE streamDate DateTime = @startDate.AddDays(-1);

// reference the pre-cooked data
// note: LOCAL is declared externally when running locally
// chakra telemetry
#IF(LOCAL)
    #DECLARE inputFileName string = @"c:\temp\ESBuiltinsData.ss";
#ELSE
    #DECLARE inputFileName string = string.Format( @"/shares/asimov.prod.data/PublicPartner/Processed/ChakraJavaScript/{0}/{1:yyyy}/{1:MM}/{0}_{1:yyyy}_{1:MM}_{1:dd}.ss", "ESBuiltinsData" , @streamDate );
#ENDIF
// output file for us to write to at the end
#IF(LOCAL)
    #DECLARE outputFileName string = @"c:\temp\ESBuiltinsData_Pivoted.ss";
#ELSE
    #DECLARE outputFileName string = string.Format( @"/shares/asimov.prod.data/PublicPartner/Processed/ChakraJavaScript/{0}/{1:yyyy}/{1:MM}/{0}_{1:yyyy}_{1:MM}_{1:dd}.ss", "ESBuiltinsData_Pivoted" , @streamDate );
#ENDIF

// Grab the data from the cooked files into live stream
inputData = 
    SELECT
        *
    FROM ( SSTREAM @inputFileName );

// Extract the data from the data json object into columns in the actual table
// (it's significantly easier to do this here than in the c# code)
ESBuiltIns2017Data_Extracted =
    SELECT inputData.Domain AS Domain,
           inputData.ApplicationName AS ApplicationName,
           inputData.MachineConfigId AS MachineConfigId,
           inputData.ActivityId AS ActivityId,
           (data["UncategorizedNameTags"]?? null) AS UncategorizedNameTags,
           (data["UncategorizedData"]?? null) AS UncategorizedData,
<<<FORALL_PRINTF(blocks,
"           (data[&quot;%name_arr_keys_item&quot;]?? &quot;&quot;) AS %name_arr_keys_item,
           (data[&quot;%name_arr_callCount_item&quot;]?? &quot;&quot;) AS %name_arr_callCount_item,
           (data[&quot;%name_arr_dmCallCount_item&quot;]?? &quot;&quot;) AS %name_arr_dmCallCount_item,
           (data[&quot;%name_arr_props_item&quot;]?? &quot;&quot;) AS %name_arr_props_item,", "\n")>>>
<<<FORALL_PRINTF(telpoints,
"           UInt64.Parse(data[&quot;%pointName&quot;]?? &quot;0&quot;) AS %pointName,", "\n")>>>
<<<FORALL_PRINTF(langfeatures,
"           UInt64.Parse(data[&quot;%pointName&quot;]?? &quot;0&quot;) AS %pointName", ",\n")>>>
    FROM inputData;
        

// Here's the trick: we get data in in the form of 
// type_arr_keys : [key1, key2, ..., keyn],
// type_arr_value1: [value1_1, value1_2, ..., value1_n],
// type_arr_value2: [value2_1, value2_2, ..., value2_n],
// type_arr_value3: [value3_1, value3_2, ..., value3_n],
// we need to pivot this data such that we get:
// type_key1_value1: value1_1,
// type_key1_value2: value2_1,
// type_key1_value3: value3_1,
// type_key2_value1: value1_2,
// ...
//
// and, if possible, this should be doable automatically for new types.
// unfortunately, doing this automatically for new types isn't currently
// viable, but it shouldn't crash on them either.
// Note that longquery is loooooooooooooooooooong. I don't currently know of a good
// way to have this derive from the normal telemetry config file, so currently it's
// just done through the application of a few regular expressions and a manual copy
// and paste into this document. The regexes, for future reference, are (as done in
// the vim style):
// 
// :%s/BLOCK.*\n//g
// :%s/ENTRY_BUILTIN([a-zA-Z0-9]*, \([a-zA-Z0-9]*\), \([a-zA-Z0-9]*\), \([a-zA-Z0-9]*\))/\1_\2_\3_present\r\1_\2_\3_props\r\1_\2_\3_callCount\r\1_\2_\3_dMCallCount/g
// :%s/ENTRY_TELPOINT(\([a-zA-Z0-9_]*\))/\1_present\r\1/g
// :%s/ENTRY_LANGFEATURE([a-zA-Z0-9]*, \([a-zA-Z0-9]*\))/\1_present\r\1/g
// :%s/\n\n/\r/g
// :%s/$/,/g
//
//
// At least, that's how it worked earlier. Now, you can just use generatequeries.py
// to create this file, and it should update everything and avoid errors.
//
// ActivityId is at the end to simplify comma handling

ESBuiltIns2017Data_Pivoted =
    PROCESS ESBuiltIns2017Data_Extracted
    PRODUCE Domain,
            ApplicationName,
            MachineConfigId,
<<<FORALL_PRINTF(builtins,
"            %baseObject_%functionResidence_%functionName_present,
            %baseObject_%functionResidence_%functionName_props,
            %baseObject_%functionResidence_%functionName_callCount,
            %baseObject_%functionResidence_%functionName_dMCallCount,", "\n")>>>
<<<FORALL_PRINTF(telpoints,
"            %pointName_present,
            %pointName,", "\n")>>>
<<<FORALL_PRINTF(langfeatures,
"            %pointName_present,
            %pointName,", "\n")>>>
            ActivityId
    USING AssocProcessor;

OUTPUT ESBuiltIns2017Data_Pivoted TO SSTREAM @outputFileName WITH STREAMEXPIRY "365";

